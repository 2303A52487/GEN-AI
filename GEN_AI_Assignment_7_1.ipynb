{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkaehl94m0lDi1n+/W1t3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52487/GEN-AI/blob/main/GEN_AI_Assignment_7_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7PXtU5H4pnMS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nijBqpGHpwCC",
        "outputId": "0dfba6d0-889f-4a62-b5a6-77cc88a95304"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(X_train.shape[1],)),  # Hidden Layer 1\n",
        "    Dense(16, activation='relu'),                                    # Hidden Layer 2\n",
        "    Dense(20, activation='relu'),                                    # Hidden Layer 3\n",
        "    Dense(10, activation='relu'),                                    # Hidden Layer 4\n",
        "    Dense(1, activation='sigmoid')                                   # Output Layer (binary classification)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOQJgyxvp1HI",
        "outputId": "9ac90488-47d6-4ba5-c4fb-8c181f425acf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=150, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ye7XHUAp4ga",
        "outputId": "464ae4eb-9824-4f73-d94e-445288144bcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.3207 - loss: 11.4325 - val_accuracy: 0.3902 - val_loss: 6.5417\n",
            "Epoch 2/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3287 - loss: 10.6122 - val_accuracy: 0.3902 - val_loss: 6.5362\n",
            "Epoch 3/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3491 - loss: 10.1461 - val_accuracy: 0.3902 - val_loss: 6.5307\n",
            "Epoch 4/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3460 - loss: 10.8604 - val_accuracy: 0.3902 - val_loss: 6.5251\n",
            "Epoch 5/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3327 - loss: 10.5512 - val_accuracy: 0.3902 - val_loss: 6.5194\n",
            "Epoch 6/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3627 - loss: 10.4864 - val_accuracy: 0.3902 - val_loss: 6.5137\n",
            "Epoch 7/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3504 - loss: 10.6813 - val_accuracy: 0.3902 - val_loss: 6.5079\n",
            "Epoch 8/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3375 - loss: 10.5754 - val_accuracy: 0.3902 - val_loss: 6.5021\n",
            "Epoch 9/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3442 - loss: 9.6722 - val_accuracy: 0.3902 - val_loss: 6.4962\n",
            "Epoch 10/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2953 - loss: 11.1334 - val_accuracy: 0.3902 - val_loss: 6.4904\n",
            "Epoch 11/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3865 - loss: 10.4405 - val_accuracy: 0.3902 - val_loss: 6.4845\n",
            "Epoch 12/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3550 - loss: 10.3343 - val_accuracy: 0.3902 - val_loss: 6.4785\n",
            "Epoch 13/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3223 - loss: 11.2804 - val_accuracy: 0.3902 - val_loss: 6.4726\n",
            "Epoch 14/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3148 - loss: 11.4524 - val_accuracy: 0.3902 - val_loss: 6.4666\n",
            "Epoch 15/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3576 - loss: 10.3635 - val_accuracy: 0.3902 - val_loss: 6.4605\n",
            "Epoch 16/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3255 - loss: 10.7797 - val_accuracy: 0.3902 - val_loss: 6.4543\n",
            "Epoch 17/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3306 - loss: 11.5172 - val_accuracy: 0.3902 - val_loss: 6.4482\n",
            "Epoch 18/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3493 - loss: 10.0876 - val_accuracy: 0.3902 - val_loss: 6.4420\n",
            "Epoch 19/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3305 - loss: 10.5303 - val_accuracy: 0.3902 - val_loss: 6.4358\n",
            "Epoch 20/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3320 - loss: 10.8593 - val_accuracy: 0.3902 - val_loss: 6.4295\n",
            "Epoch 21/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3448 - loss: 10.7676 - val_accuracy: 0.3821 - val_loss: 6.4233\n",
            "Epoch 22/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3306 - loss: 10.3369 - val_accuracy: 0.3821 - val_loss: 6.4169\n",
            "Epoch 23/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3490 - loss: 10.8231 - val_accuracy: 0.3821 - val_loss: 6.4105\n",
            "Epoch 24/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3723 - loss: 10.2458 - val_accuracy: 0.3821 - val_loss: 6.4042\n",
            "Epoch 25/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3169 - loss: 10.3541 - val_accuracy: 0.3821 - val_loss: 6.3978\n",
            "Epoch 26/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3427 - loss: 11.0157 - val_accuracy: 0.3821 - val_loss: 6.3914\n",
            "Epoch 27/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3445 - loss: 10.0439 - val_accuracy: 0.3821 - val_loss: 6.3849\n",
            "Epoch 28/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3554 - loss: 10.1622 - val_accuracy: 0.3821 - val_loss: 6.3783\n",
            "Epoch 29/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3244 - loss: 11.1246 - val_accuracy: 0.3821 - val_loss: 6.3716\n",
            "Epoch 30/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3562 - loss: 10.6186 - val_accuracy: 0.3821 - val_loss: 6.3649\n",
            "Epoch 31/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3406 - loss: 10.8254 - val_accuracy: 0.3821 - val_loss: 6.3583\n",
            "Epoch 32/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3535 - loss: 9.8992 - val_accuracy: 0.3821 - val_loss: 6.3516\n",
            "Epoch 33/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3239 - loss: 10.5049 - val_accuracy: 0.3821 - val_loss: 6.3449\n",
            "Epoch 34/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3448 - loss: 9.6961 - val_accuracy: 0.3821 - val_loss: 6.3381\n",
            "Epoch 35/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3794 - loss: 9.8403 - val_accuracy: 0.3821 - val_loss: 6.3313\n",
            "Epoch 36/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3455 - loss: 10.5969 - val_accuracy: 0.3821 - val_loss: 6.3244\n",
            "Epoch 37/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3496 - loss: 9.5273 - val_accuracy: 0.3821 - val_loss: 6.3175\n",
            "Epoch 38/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3769 - loss: 9.2431 - val_accuracy: 0.3821 - val_loss: 6.3106\n",
            "Epoch 39/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3488 - loss: 10.3299 - val_accuracy: 0.3821 - val_loss: 6.3036\n",
            "Epoch 40/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3476 - loss: 10.3035 - val_accuracy: 0.3821 - val_loss: 6.2967\n",
            "Epoch 41/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3581 - loss: 9.9892 - val_accuracy: 0.3821 - val_loss: 6.2897\n",
            "Epoch 42/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3519 - loss: 9.6292 - val_accuracy: 0.3821 - val_loss: 6.2826\n",
            "Epoch 43/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3528 - loss: 10.2109 - val_accuracy: 0.3821 - val_loss: 6.2756\n",
            "Epoch 44/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3649 - loss: 9.4422 - val_accuracy: 0.3821 - val_loss: 6.2685\n",
            "Epoch 45/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3741 - loss: 9.4142 - val_accuracy: 0.3821 - val_loss: 6.2613\n",
            "Epoch 46/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3323 - loss: 10.1143 - val_accuracy: 0.3821 - val_loss: 6.2541\n",
            "Epoch 47/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3618 - loss: 10.4367 - val_accuracy: 0.3821 - val_loss: 6.2469\n",
            "Epoch 48/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3651 - loss: 10.5192 - val_accuracy: 0.3821 - val_loss: 6.2397\n",
            "Epoch 49/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3506 - loss: 10.0977 - val_accuracy: 0.3821 - val_loss: 6.2325\n",
            "Epoch 50/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3520 - loss: 10.0016 - val_accuracy: 0.3821 - val_loss: 6.2253\n",
            "Epoch 51/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3363 - loss: 10.3807 - val_accuracy: 0.3821 - val_loss: 6.2180\n",
            "Epoch 52/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3599 - loss: 10.1081 - val_accuracy: 0.3821 - val_loss: 6.2107\n",
            "Epoch 53/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3172 - loss: 10.0024 - val_accuracy: 0.3821 - val_loss: 6.2035\n",
            "Epoch 54/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3485 - loss: 9.1304 - val_accuracy: 0.3821 - val_loss: 6.1960\n",
            "Epoch 55/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3489 - loss: 9.4095 - val_accuracy: 0.3821 - val_loss: 6.1885\n",
            "Epoch 56/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3712 - loss: 9.3228 - val_accuracy: 0.3821 - val_loss: 6.1811\n",
            "Epoch 57/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3301 - loss: 10.2329 - val_accuracy: 0.3821 - val_loss: 6.1737\n",
            "Epoch 58/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3418 - loss: 9.6628 - val_accuracy: 0.3821 - val_loss: 6.1662\n",
            "Epoch 59/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3273 - loss: 10.2347 - val_accuracy: 0.3821 - val_loss: 6.1587\n",
            "Epoch 60/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3461 - loss: 10.7086 - val_accuracy: 0.3821 - val_loss: 6.1512\n",
            "Epoch 61/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3181 - loss: 10.4851 - val_accuracy: 0.3821 - val_loss: 6.1436\n",
            "Epoch 62/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3229 - loss: 10.4932 - val_accuracy: 0.3821 - val_loss: 6.1360\n",
            "Epoch 63/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3390 - loss: 10.5077 - val_accuracy: 0.3821 - val_loss: 6.1285\n",
            "Epoch 64/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3748 - loss: 9.8239 - val_accuracy: 0.3821 - val_loss: 6.1208\n",
            "Epoch 65/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3530 - loss: 9.8080 - val_accuracy: 0.3821 - val_loss: 6.1130\n",
            "Epoch 66/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3824 - loss: 9.5951 - val_accuracy: 0.3821 - val_loss: 6.1053\n",
            "Epoch 67/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3496 - loss: 9.3583 - val_accuracy: 0.3821 - val_loss: 6.0975\n",
            "Epoch 68/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3400 - loss: 9.8684 - val_accuracy: 0.3821 - val_loss: 6.0896\n",
            "Epoch 69/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3485 - loss: 10.7013 - val_accuracy: 0.3821 - val_loss: 6.0818\n",
            "Epoch 70/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3466 - loss: 9.0267 - val_accuracy: 0.3821 - val_loss: 6.0738\n",
            "Epoch 71/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3652 - loss: 9.3004 - val_accuracy: 0.3821 - val_loss: 6.0658\n",
            "Epoch 72/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3557 - loss: 9.2317 - val_accuracy: 0.3821 - val_loss: 6.0579\n",
            "Epoch 73/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3285 - loss: 10.0689 - val_accuracy: 0.3821 - val_loss: 6.0501\n",
            "Epoch 74/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3531 - loss: 9.9285 - val_accuracy: 0.3821 - val_loss: 6.0422\n",
            "Epoch 75/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3267 - loss: 9.5292 - val_accuracy: 0.3821 - val_loss: 6.0342\n",
            "Epoch 76/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3755 - loss: 9.0783 - val_accuracy: 0.3821 - val_loss: 6.0262\n",
            "Epoch 77/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3183 - loss: 10.0144 - val_accuracy: 0.3821 - val_loss: 6.0181\n",
            "Epoch 78/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3482 - loss: 9.9957 - val_accuracy: 0.3821 - val_loss: 6.0101\n",
            "Epoch 79/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3425 - loss: 10.4262 - val_accuracy: 0.3821 - val_loss: 6.0021\n",
            "Epoch 80/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3257 - loss: 10.5912 - val_accuracy: 0.3821 - val_loss: 5.9939\n",
            "Epoch 81/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3155 - loss: 9.9864 - val_accuracy: 0.3821 - val_loss: 5.9857\n",
            "Epoch 82/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3532 - loss: 10.0743 - val_accuracy: 0.3821 - val_loss: 5.9775\n",
            "Epoch 83/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3658 - loss: 8.6344 - val_accuracy: 0.3821 - val_loss: 5.9694\n",
            "Epoch 84/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3339 - loss: 9.7468 - val_accuracy: 0.3821 - val_loss: 5.9613\n",
            "Epoch 85/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3534 - loss: 9.3239 - val_accuracy: 0.3821 - val_loss: 5.9530\n",
            "Epoch 86/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3311 - loss: 10.2113 - val_accuracy: 0.3821 - val_loss: 5.9448\n",
            "Epoch 87/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3345 - loss: 9.7046 - val_accuracy: 0.3821 - val_loss: 5.9366\n",
            "Epoch 88/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3257 - loss: 9.5809 - val_accuracy: 0.3821 - val_loss: 5.9282\n",
            "Epoch 89/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3556 - loss: 9.4660 - val_accuracy: 0.3821 - val_loss: 5.9200\n",
            "Epoch 90/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3469 - loss: 8.8224 - val_accuracy: 0.3821 - val_loss: 5.9115\n",
            "Epoch 91/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3182 - loss: 10.0356 - val_accuracy: 0.3821 - val_loss: 5.9031\n",
            "Epoch 92/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3358 - loss: 9.3035 - val_accuracy: 0.3821 - val_loss: 5.8946\n",
            "Epoch 93/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3439 - loss: 9.4482 - val_accuracy: 0.3821 - val_loss: 5.8861\n",
            "Epoch 94/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3719 - loss: 9.7077 - val_accuracy: 0.3821 - val_loss: 5.8775\n",
            "Epoch 95/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3309 - loss: 9.5902 - val_accuracy: 0.3821 - val_loss: 5.8689\n",
            "Epoch 96/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3621 - loss: 10.0029 - val_accuracy: 0.3821 - val_loss: 5.8603\n",
            "Epoch 97/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3492 - loss: 9.5904 - val_accuracy: 0.3821 - val_loss: 5.8517\n",
            "Epoch 98/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3360 - loss: 8.8394 - val_accuracy: 0.3821 - val_loss: 5.8430\n",
            "Epoch 99/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3466 - loss: 9.7158 - val_accuracy: 0.3821 - val_loss: 5.8344\n",
            "Epoch 100/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3238 - loss: 9.7636 - val_accuracy: 0.3821 - val_loss: 5.8259\n",
            "Epoch 101/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3370 - loss: 9.2229 - val_accuracy: 0.3821 - val_loss: 5.8173\n",
            "Epoch 102/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3465 - loss: 9.1967 - val_accuracy: 0.3821 - val_loss: 5.8086\n",
            "Epoch 103/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3352 - loss: 9.4522 - val_accuracy: 0.3821 - val_loss: 5.7998\n",
            "Epoch 104/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3508 - loss: 8.8892 - val_accuracy: 0.3821 - val_loss: 5.7910\n",
            "Epoch 105/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3477 - loss: 9.5789 - val_accuracy: 0.3821 - val_loss: 5.7825\n",
            "Epoch 106/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3563 - loss: 9.6222 - val_accuracy: 0.3821 - val_loss: 5.7738\n",
            "Epoch 107/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3429 - loss: 9.0481 - val_accuracy: 0.3821 - val_loss: 5.7650\n",
            "Epoch 108/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3328 - loss: 10.4813 - val_accuracy: 0.3821 - val_loss: 5.7564\n",
            "Epoch 109/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3232 - loss: 9.5930 - val_accuracy: 0.3821 - val_loss: 5.7476\n",
            "Epoch 110/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3387 - loss: 9.1536 - val_accuracy: 0.3821 - val_loss: 5.7389\n",
            "Epoch 111/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3662 - loss: 9.0137 - val_accuracy: 0.3821 - val_loss: 5.7301\n",
            "Epoch 112/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3500 - loss: 8.4094 - val_accuracy: 0.3821 - val_loss: 5.7212\n",
            "Epoch 113/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3354 - loss: 9.3708 - val_accuracy: 0.3821 - val_loss: 5.7124\n",
            "Epoch 114/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3271 - loss: 9.8245 - val_accuracy: 0.3821 - val_loss: 5.7036\n",
            "Epoch 115/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3437 - loss: 8.6070 - val_accuracy: 0.3821 - val_loss: 5.6948\n",
            "Epoch 116/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3528 - loss: 9.4550 - val_accuracy: 0.3821 - val_loss: 5.6858\n",
            "Epoch 117/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3604 - loss: 8.7831 - val_accuracy: 0.3821 - val_loss: 5.6770\n",
            "Epoch 118/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3641 - loss: 8.1296 - val_accuracy: 0.3821 - val_loss: 5.6679\n",
            "Epoch 119/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3311 - loss: 9.7488 - val_accuracy: 0.3821 - val_loss: 5.6590\n",
            "Epoch 120/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3602 - loss: 9.3289 - val_accuracy: 0.3821 - val_loss: 5.6500\n",
            "Epoch 121/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3580 - loss: 8.5394 - val_accuracy: 0.3821 - val_loss: 5.6411\n",
            "Epoch 122/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3412 - loss: 9.4146 - val_accuracy: 0.3821 - val_loss: 5.6320\n",
            "Epoch 123/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3812 - loss: 8.3233 - val_accuracy: 0.3821 - val_loss: 5.6229\n",
            "Epoch 124/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3411 - loss: 9.0473 - val_accuracy: 0.3821 - val_loss: 5.6140\n",
            "Epoch 125/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3533 - loss: 9.4322 - val_accuracy: 0.3821 - val_loss: 5.6049\n",
            "Epoch 126/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3581 - loss: 9.3705 - val_accuracy: 0.3821 - val_loss: 5.5959\n",
            "Epoch 127/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3421 - loss: 9.4807 - val_accuracy: 0.3821 - val_loss: 5.5869\n",
            "Epoch 128/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3517 - loss: 8.8102 - val_accuracy: 0.3821 - val_loss: 5.5778\n",
            "Epoch 129/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3456 - loss: 8.7148 - val_accuracy: 0.3821 - val_loss: 5.5686\n",
            "Epoch 130/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3472 - loss: 9.3291 - val_accuracy: 0.3821 - val_loss: 5.5594\n",
            "Epoch 131/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3228 - loss: 9.1493 - val_accuracy: 0.3821 - val_loss: 5.5502\n",
            "Epoch 132/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3372 - loss: 9.2383 - val_accuracy: 0.3821 - val_loss: 5.5410\n",
            "Epoch 133/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3504 - loss: 9.6012 - val_accuracy: 0.3821 - val_loss: 5.5318\n",
            "Epoch 134/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3181 - loss: 9.6652 - val_accuracy: 0.3821 - val_loss: 5.5226\n",
            "Epoch 135/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3402 - loss: 8.8464 - val_accuracy: 0.3821 - val_loss: 5.5133\n",
            "Epoch 136/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3691 - loss: 9.3543 - val_accuracy: 0.3821 - val_loss: 5.5040\n",
            "Epoch 137/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3295 - loss: 8.8189 - val_accuracy: 0.3821 - val_loss: 5.4946\n",
            "Epoch 138/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3362 - loss: 8.9363 - val_accuracy: 0.3821 - val_loss: 5.4852\n",
            "Epoch 139/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3389 - loss: 8.6519 - val_accuracy: 0.3821 - val_loss: 5.4758\n",
            "Epoch 140/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3318 - loss: 9.4890 - val_accuracy: 0.3821 - val_loss: 5.4664\n",
            "Epoch 141/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3479 - loss: 9.0477 - val_accuracy: 0.3821 - val_loss: 5.4571\n",
            "Epoch 142/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3792 - loss: 8.2411 - val_accuracy: 0.3821 - val_loss: 5.4476\n",
            "Epoch 143/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3462 - loss: 8.8685 - val_accuracy: 0.3821 - val_loss: 5.4382\n",
            "Epoch 144/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3245 - loss: 8.1741 - val_accuracy: 0.3821 - val_loss: 5.4287\n",
            "Epoch 145/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3763 - loss: 8.6501 - val_accuracy: 0.3821 - val_loss: 5.4194\n",
            "Epoch 146/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3549 - loss: 8.6931 - val_accuracy: 0.3821 - val_loss: 5.4100\n",
            "Epoch 147/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3365 - loss: 8.6752 - val_accuracy: 0.3821 - val_loss: 5.4004\n",
            "Epoch 148/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3296 - loss: 9.1370 - val_accuracy: 0.3821 - val_loss: 5.3910\n",
            "Epoch 149/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3535 - loss: 8.6285 - val_accuracy: 0.3821 - val_loss: 5.3815\n",
            "Epoch 150/150\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3228 - loss: 9.4712 - val_accuracy: 0.3821 - val_loss: 5.3721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Test Accuracy: {accuracy:.2f}')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "R1-BOeZprtQD",
        "outputId": "ab35619e-58f2-42ab-c92f-33c9c73c47dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Test Accuracy: 0.36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.35\n",
            "Recall: 0.95\n",
            "F1 Score: 0.51\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.03      0.06        99\n",
            "           1       0.35      0.95      0.51        55\n",
            "\n",
            "    accuracy                           0.36       154\n",
            "   macro avg       0.43      0.49      0.28       154\n",
            "weighted avg       0.45      0.36      0.22       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/diabetes_ann_model.h5')\n",
        "\n",
        "\n",
        "loaded_model = keras.models.load_model('/content/diabetes_ann_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_B480m9p-to",
        "outputId": "6e64e0d2-58b2-4f9d-958c-93e8e4473d93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = np.array([X_test[0]])\n",
        "\n",
        "prediction = (loaded_model.predict(sample_data) > 0.5).astype(int)\n",
        "print(f'Prediction for sample data: {prediction[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlHje_TFqB8R",
        "outputId": "ce50ba1f-016e-4863-acc6-6f8431f49a30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "Prediction for sample data: 1\n"
          ]
        }
      ]
    }
  ]
}